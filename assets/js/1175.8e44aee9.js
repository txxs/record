(window.webpackJsonp=window.webpackJsonp||[]).push([[1175],{1568:function(e,t,r){"use strict";r.r(t);var v=r(13),_=Object(v.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("p",[e._v("问题本质都在于你的消费端可能出了问题，不消费或消费的太慢！更可怕的是由于积压时间太长，导致如果起初还设置了TTL后失效了怎么办？")]),e._v(" "),r("h1",{attrs:{id:"消息积压"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消息积压"}},[e._v("#")]),e._v(" 消息积压")]),e._v(" "),r("p",[e._v("其实数据积压的问题是架构设计不合理。")]),e._v(" "),r("blockquote",[r("p",[e._v("丢失的数据是通过日志找回来,如果日志也找不到了 那就没招了")])]),e._v(" "),r("p",[e._v("一般这时，只能操作临时紧急扩容了，具体操作步骤和思路如下：")]),e._v(" "),r("ol",[r("li",[e._v("先修复consumer，确保恢复消费速度，然后将现有cnosumer都停掉")]),e._v(" "),r("li",[e._v("新建一个topic，partition是原来10倍，临时建立好原先10倍或者20倍的queue")]),e._v(" "),r("li",[e._v("然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue")]),e._v(" "),r("li",[e._v("接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据")]),e._v(" "),r("li",[e._v("这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据")]),e._v(" "),r("li",[e._v("等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息")])]),e._v(" "),r("h1",{attrs:{id:"消息丢失"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#消息丢失"}},[e._v("#")]),e._v(" 消息丢失")]),e._v(" "),r("p",[e._v("假设用rabbitmq，可设置TTL，积压超时后消息就没了，数据也就丢了。注意此时，并非数据大量积压在MQ，而是大量数据直接搞丢了。")]),e._v(" "),r("p",[e._v("可以采取批量重导，就是大量积压时，就直接丢弃数据，然后等高峰期后，比如半夜，将丢失的那批数据，写个程序查出来，然后重新灌入MQ，把白天丢的数据补回来。")])])}),[],!1,null,null,null);t.default=_.exports}}]);